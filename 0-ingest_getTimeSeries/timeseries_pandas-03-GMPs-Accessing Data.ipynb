{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Accessing Data\n\nAs pandas is built on Python, any means available in Python can be used to retrieve data from outside source. This really makes the possibility of the data that can be accessed unlimited including text files, excel spreadsheets, web sites and services, databases and cloud based services.",
   "metadata": {
    "cell_id": "99f77d17-64c0-4f8b-ae2f-c6e2620a45bb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Setting up the Python notebook",
   "metadata": {
    "cell_id": "00001-ea2b4ed9-e3b8-4f06-8efa-3b7d60a4aec8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00002-1056837d-b35e-4bd5-a833-befc0b2928e9",
    "deepnote_cell_type": "code"
   },
   "source": "# import pandas and numpy\nimport numpy as np\nimport pandas as pd\n\n# set some pandas options for controlling output\npd.set_option('display.notebook_repr_html', False)\npd.set_option('display.max_columns',10)\npd.set_option('display.max_rows',10)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## CSV & Text/Tabular Format",
   "metadata": {
    "cell_id": "00003-336ff17b-dd42-4be8-b2a3-fef3410d7cbb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-3c6dccac-cbad-410c-85de-49f9b9b4d9f0",
    "deepnote_cell_type": "code"
   },
   "source": "# view the first five lines of data/msft.csv\n! head -n 5 ../../data/msft.csv # OS/Linux\n# !type ..\\..\\data\\msft.csv     # on windows",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Date,Open,High,Low,Close,Volume,Adj Close\r\n2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Reading a CSV file into DataFrame",
   "metadata": {
    "cell_id": "00005-1ea442d0-72fe-4a2a-9d09-4fb58d0fce84",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-3c0b2328-a749-4c85-983c-da92f6e397b7",
    "deepnote_cell_type": "code"
   },
   "source": "# read in msft.csv into a DataFrame\nmsft = pd.read_csv(\"../../data/msft.csv\")\nmsft.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   Open   High    Low  Close   Volume  Adj Close\n0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00007-a2f0b582-c551-451c-81c6-556f83660323",
    "deepnote_cell_type": "code"
   },
   "source": "# specifying the index column\nmsft = pd.read_csv(\"../../data/msft.csv\", index_col=0)\nmsft.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "             Open   High    Low  Close   Volume  Adj Close\nDate                                                      \n2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "The data field is now the index however because of this it is also not a column data. If you want to use the date as a column, you will need to create a new column and assign the index labels to that column.",
   "metadata": {
    "cell_id": "00008-d080fe2d-ae4c-406d-a5d3-ebac04c02c4e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-5e0642c8-b11a-4067-828c-6d8325002457",
    "deepnote_cell_type": "code"
   },
   "source": "# examine the types of the columns in the DataFrame\nmsft.dtypes",
   "outputs": [
    {
     "data": {
      "text/plain": "Open         float64\nHigh         float64\nLow          float64\nClose        float64\nVolume         int64\nAdj Close    float64\ndtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-ecd94bbd-37de-42a9-bbbd-4052ea56e975",
    "deepnote_cell_type": "code"
   },
   "source": "# to force type of columns, use the dtypes parameter\n# following forces the column to be float64\nmsft = pd.read_csv(\"../../data/msft.csv\", dtype={'Volume': np.float64})\nmsft.dtypes",
   "outputs": [
    {
     "data": {
      "text/plain": "Date          object\nOpen         float64\nHigh         float64\nLow          float64\nClose        float64\nVolume       float64\nAdj Close    float64\ndtype: object"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Specifying column names",
   "metadata": {
    "cell_id": "00011-31f51ee3-9512-4105-8a44-eb7d9a3f84b8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00012-ec4c5ac2-116a-4997-9459-bedee8b6bb0d",
    "deepnote_cell_type": "code"
   },
   "source": "# specify a new set of names for the columns\n# all lower case, remove space in Adj Close\n# also, header = 0 skips the header row\ndf = pd.read_csv(\"../../data/msft.csv\",header=0,names=['open','high','low','close','volume','adjclose'])\ndf.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "             open   high    low  close   volume  adjclose\n2014-07-21  83.46  83.53  81.81  81.93  2359300     81.93\n2014-07-18  83.30  83.40  82.52  83.35  4020800     83.35\n2014-07-17  84.35  84.63  83.33  83.63  1974000     83.63\n2014-07-16  83.77  84.91  83.66  84.91  1755600     84.91\n2014-07-15  84.30  84.38  83.20  83.58  1874700     83.58"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00013-84b9f186-4fbf-4dc5-8eef-d74182eaa445",
    "deepnote_cell_type": "code"
   },
   "source": "# read in data only in the Date and close columns,\n# use Date as the inde\ndf2 = pd.read_csv(\"../../data/msft.csv\",usecols=['Date','Close'],index_col=['Date'])\ndf2.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "            Close\nDate             \n2014-07-21  81.93\n2014-07-18  83.35\n2014-07-17  83.63\n2014-07-16  84.91\n2014-07-15  83.58"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Saving DataFrame to a CSV file",
   "metadata": {
    "cell_id": "00014-19a45f15-473b-42be-b7b4-8f0a2ec03c8b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00015-ba9b17e9-cb59-4d34-9cf8-77f6359112ba",
    "deepnote_cell_type": "code"
   },
   "source": "# save df2 to a new csv file\n# also specify naming the index as date\ndf2.to_csv(\"../../data/msft_modified.csv\",index_label='date')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "It was necessary to tell the method that the index label should be saved with a column name of date using index_label=date. Otherwise, the index does not have a name added to the first row of the file, which makes it difficult to read back properly.",
   "metadata": {
    "cell_id": "00016-ed875ffb-38d7-48d2-9f9e-deff25bc640b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-d0413597-8b76-4faa-8028-ac829fb73aed",
    "deepnote_cell_type": "code"
   },
   "source": "# view the start of the file just saved\n!head ../../data/msft_modified.csv",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "date,Close\r\n2014-07-21,81.93\r\n2014-07-18,83.35\r\n2014-07-17,83.63\r\n2014-07-16,84.91\r\n2014-07-15,83.58\r\n2014-07-14,84.4\r\n2014-07-11,83.35\r\n2014-07-10,83.42\r\n2014-07-09,85.5\r\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### General Field-Delimited Data",
   "metadata": {
    "cell_id": "00018-eb42184d-21bc-4463-a60c-71b9f4192dbf",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00019-f372dc4d-7ff3-4044-81e0-7afdfb2bf186",
    "deepnote_cell_type": "code"
   },
   "source": "# use read_table with sep=',' to read a csv\ndf=pd.read_table(\"../../data/msft.csv\",sep=',')\ndf.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   Open   High    Low  Close   Volume  Adj Close\n0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00020-59473df5-5b05-43ce-aa73-011bebb98511",
    "deepnote_cell_type": "code"
   },
   "source": "# save as pipe delimited\ndf.to_csv(\"../../data/msft_piped.txt\",sep='|')\n# check if it worked\n!head -n 5 ../../data/msft_piped.txt",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "|Date|Open|High|Low|Close|Volume|Adj Close\r\n0|2014-07-21|83.46|83.53|81.81|81.93|2359300|81.93\r\n1|2014-07-18|83.3|83.4|82.52|83.35|4020800|83.35\r\n2|2014-07-17|84.35|84.63|83.33|83.63|1974000|83.63\r\n3|2014-07-16|83.77|84.91|83.66|84.91|1755600|84.91\r\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Handling noise rows in a dataset\n\nSometimes, data in a field-delimited file may contain erroneous headers and footers. Examples can be company information at the top, such as invoice number, addresses and summary footers. Sometimes data is stored on ever other line. These situations will cause error when pandas tries to open files. To handle these scenarios some useful parameters can be used.",
   "metadata": {
    "cell_id": "00021-d6ecd1ba-906c-49d7-b13f-0ec88e0e2deb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00022-3fbabbfa-7e5a-4311-9e11-d756e4ad3fe2",
    "deepnote_cell_type": "code"
   },
   "source": "# messy file\n!head ../../data/msft2.csv  # Linux",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "This is fun because the data does not start on the first line\r\nDate,Open,High,Low,Close,Volume,Adj Close\r\n\r\nAnd there is space between the header row and data\r\n2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n2014-07-15,84.30,84.38,83.20,83.58,1874700,83.58\r\n2014-07-14,83.66,84.64,83.11,84.40,1432100,84.40\r\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00023-cae6ae97-78c9-4032-b26e-e3d2cfbb6334",
    "deepnote_cell_type": "code"
   },
   "source": "# read, but skip rows 0,2 and 3\ndf = pd.read_csv(\"../../data/msft2.csv\",skiprows=[0,2,3])\ndf",
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   Open   High    Low  Close   Volume  Adj Close\n0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58\n5  2014-07-14  83.66  84.64  83.11  84.40  1432100      84.40\n6  2014-07-11  83.55  83.98  82.85  83.35  2001400      83.35\n7  2014-07-10  85.20  85.57  83.36  83.42  2713300      83.42\n8  2014-07-09  84.83  85.79  84.76  85.50  1540700      85.50"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Another common situation is where a file has content at the end of the file which should be ignored to prevent an error, such as the following:",
   "metadata": {
    "cell_id": "00024-f82e03ff-f95f-4042-a349-15cff3924f91",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00025-45a5cadb-b8fe-44bb-9be6-214ea72f1516",
    "deepnote_cell_type": "code"
   },
   "source": "# another messy  file with mess at the end\n!cat ../../data/msft_with_footer.csv # osx / Linux",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Date,Open,High,Low,Close,Volume,Adj Close\r\n2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n\r\nUh oh, there is stuff at the end."
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00026-d2f06672-350a-42cc-b4bb-3af65af88d60",
    "deepnote_cell_type": "code"
   },
   "source": "# skip only two lines at the end\n# engine parameter to force python implementation rather than default c implementation\ndf = pd.read_csv(\"../../data/msft_with_footer.csv\",skipfooter=2,engine='python')\ndf",
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   Open   High    Low  Close   Volume  Adj Close\n0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00027-963d786f-dcdd-46c6-a6a9-3e14d8cfe78c",
    "deepnote_cell_type": "code"
   },
   "source": "# only process the first three rows\npd.read_csv(\"../../data/msft.csv\",nrows=3)",
   "outputs": [
    {
     "data": {
      "text/plain": "         Date   Open   High    Low  Close   Volume  Adj Close\n0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00028-cce881c9-dac6-4e5f-839b-1c5af270fbd2",
    "deepnote_cell_type": "code"
   },
   "source": "# skip 100 lines, then only process the next five\npd.read_csv(\"../../data/msft.csv\", skiprows=100, nrows=5, header=0,names=['open','high','low','close','vol','adjclose'])",
   "outputs": [
    {
     "data": {
      "text/plain": "             open   high    low  close      vol  adjclose\n2014-03-03  80.35  81.31  79.91  79.97  5004100     77.40\n2014-02-28  82.40  83.42  82.17  83.42  2853200     80.74\n2014-02-27  84.06  84.63  81.63  82.00  3676800     79.36\n2014-02-26  82.92  84.03  82.43  83.81  2623600     81.12\n2014-02-25  83.80  83.80  81.72  83.08  3579100     80.41"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Reading and Writing data in Excel Format\n\npandas support reading data in Excel 2003 and newer formats using the pd.read_excel() function or via ExcelFile class.",
   "metadata": {
    "cell_id": "00029-ddcdc77a-811e-4110-a21a-06677996c1ea",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00030-16be324a-31d0-4f24-a16c-e9392714688d",
    "deepnote_cell_type": "code"
   },
   "source": "# read excel file\n# only reads first sheet\ndf = pd.read_excel(\"../../data/stocks.xlsx\")\ndf.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "        Date   Open   High    Low  Close   Volume  Adj Close\n0 2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n1 2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n2 2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n3 2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n4 2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00031-c11deb2d-8e35-4449-aaec-54140177cda2",
    "deepnote_cell_type": "code"
   },
   "source": "# read from the appl worksheet\naapl = pd.read_excel(\"../../data/stocks.xlsx\", sheetname='aapl')\naapl.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "        Date   Open   High    Low  Close    Volume  Adj Close\n0 2014-07-21  94.99  95.00  93.72  93.94  38887700      93.94\n1 2014-07-18  93.62  94.74  93.02  94.43  49898600      94.43\n2 2014-07-17  95.03  95.28  92.57  93.09  57152000      93.09\n3 2014-07-16  96.97  97.10  94.74  94.78  53396300      94.78\n4 2014-07-15  96.80  96.85  95.03  95.32  45477900      95.32"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00032-f1ad4f25-b332-478b-8af7-84d397034b1d",
    "deepnote_cell_type": "code"
   },
   "source": "# save to excel file in worksheet sheet1\ndf.to_excel(\"../../data/stocks2.xlsx\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00033-e7e755db-5e5c-487a-8724-85f8747de65e",
    "deepnote_cell_type": "code"
   },
   "source": "# write making the worksheet name MSFT\ndf.to_excel(\"../../data/stocks_msft.xlsx\", sheet_name='MSFT')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "To write more than one DataFrame to a single Excel file and each DataFrame object on a separate worksheet use the ExcelWriter object along with the with keyword.",
   "metadata": {
    "cell_id": "00034-f340e8ad-82b2-4b35-9861-3dc15894400f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00035-6c3d4f56-44a4-4fcd-a284-b18275de771e",
    "deepnote_cell_type": "code"
   },
   "source": "from pandas import ExcelWriter\nwith ExcelWriter(\"../../data/all_stocks.xls\") as writer:\n    aapl.to_excel(writer,sheet_name='AAPL')\n    df.to_excel(writer,sheet_name='MSFT')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00036-36bd6769-a461-4a91-b0cb-f3b3ea7131e3",
    "deepnote_cell_type": "code"
   },
   "source": "# write to xlsx\ndf.to_excel(\"../../data/msft2.xlsx\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Reading and Writing JSON files\n\npandas can read and write data stored on JSON format.",
   "metadata": {
    "cell_id": "00037-4cb0a62e-ad6e-42d6-b356-c185a3cd8cce",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00038-61b7b27e-c67f-4ca0-9c65-ce26a9f322ef",
    "deepnote_cell_type": "code"
   },
   "source": "# write the excel data to a JSON file\ndf.head().to_json(\"../../data/stocks.json\")\n!cat ../../data/stocks.json",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\"Date\":{\"0\":1405900800000,\"1\":1405641600000,\"2\":1405555200000,\"3\":1405468800000,\"4\":1405382400000},\"Open\":{\"0\":83.46,\"1\":83.3,\"2\":84.35,\"3\":83.77,\"4\":84.3},\"High\":{\"0\":83.53,\"1\":83.4,\"2\":84.63,\"3\":84.91,\"4\":84.38},\"Low\":{\"0\":81.81,\"1\":82.52,\"2\":83.33,\"3\":83.66,\"4\":83.2},\"Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58},\"Volume\":{\"0\":2359300,\"1\":4020800,\"2\":1974000,\"3\":1755600,\"4\":1874700},\"Adj Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58}}"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00039-c3a90123-e3c7-409a-a5b1-58768536ba33",
    "deepnote_cell_type": "code"
   },
   "source": "# read data in from JSON\ndf_from_json = pd.read_json(\"../../data/stocks.json\")\ndf_from_json.head(5)",
   "outputs": [
    {
     "data": {
      "text/plain": "   Adj Close  Close       Date   High    Low   Open   Volume\n0      81.93  81.93 2014-07-21  83.53  81.81  83.46  2359300\n1      83.35  83.35 2014-07-18  83.40  82.52  83.30  4020800\n2      83.63  83.63 2014-07-17  84.63  83.33  84.35  1974000\n3      84.91  84.91 2014-07-16  84.91  83.66  83.77  1755600\n4      83.58  83.58 2014-07-15  84.38  83.20  84.30  1874700"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "Notice two slight differences here caused by the reading / writing of data from JSON. First the columns have been reordered alphabetically. Second, the index for DataFram although containing contnet, is sorted as a string.",
   "metadata": {
    "cell_id": "00040-3563cb20-0f5e-4e22-8a40-81c214335903",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Reading HTML data from the web\n\nUnderneath the covers pandas makes use of LXML, Html5Lib and BeautifulSoup4 packages.",
   "metadata": {
    "cell_id": "00041-97fd974c-1198-4ca1-825c-c0b8a55a701f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00042-65648c73-e32e-4a5b-8ab0-396275a8c3bd",
    "deepnote_cell_type": "code"
   },
   "source": "# url to read\nurl = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n# read it\nbanks = pd.read_html(url)\n# examine a subset of the first table read\nbanks[0][0:5].ix[:,0:4]",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n  \n"
    },
    {
     "data": {
      "text/plain": "                                           Bank Name                City  ST  \\\n0    The Farmers and Merchants State Bank of Argonia             Argonia  KS   \n1                                Fayette County Bank          Saint Elmo  IL   \n2  Guaranty Bank, (d/b/a BestBank in Georgia & Mi...           Milwaukee  WI   \n3                                     First NBC Bank         New Orleans  LA   \n4                                      Proficio Bank  Cottonwood Heights  UT   \n\n    CERT  \n0  17719  \n1   1802  \n2  30003  \n3  58302  \n4  35495  "
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00043-fcf97e7b-e5d7-48ca-8634-8d3ad983b1d5",
    "deepnote_cell_type": "code"
   },
   "source": "# write to html\n# read the stock data\ndf=pd.read_excel(\"../../data/stocks.xlsx\")\n# write first 2 rows to HTML\ndf.head(2).to_html(\"../../data/stocks.html\")\n# check\n!head -n 28 ../../data/stocks.html",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<table border=\"1\" class=\"dataframe\">\r\n  <thead>\r\n    <tr style=\"text-align: right;\">\r\n      <th></th>\r\n      <th>Date</th>\r\n      <th>Open</th>\r\n      <th>High</th>\r\n      <th>Low</th>\r\n      <th>Close</th>\r\n      <th>Volume</th>\r\n      <th>Adj Close</th>\r\n    </tr>\r\n  </thead>\r\n  <tbody>\r\n    <tr>\r\n      <th>0</th>\r\n      <td>2014-07-21</td>\r\n      <td>83.46</td>\r\n      <td>83.53</td>\r\n      <td>81.81</td>\r\n      <td>81.93</td>\r\n      <td>2359300</td>\r\n      <td>81.93</td>\r\n    </tr>\r\n    <tr>\r\n      <th>1</th>\r\n      <td>2014-07-18</td>\r\n      <td>83.30</td>\r\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Reading and Writing HDF5 format files\n\nHDF5 is a data model, library and file format to store and manage data. It is commonly used in scientific computing environments. It supports an unlimited variety of data types and is designed for flexible and efficient I/O and for high volume and complex data.\n\nHDF5 is portable and extensible allowing applications to evolve in their use of HDF5. HDF5 technology suite includes tools and applications to manage, manipulate, view and analyse data in HDF5 format.\n\nHDF5 is:\n\n* A Versatile data model that can represent very complex data objects and wide variety of metadata\n* A completely portable file format with no limit on the number or size of data objects in a collection\n* A Software library that runs on range of computational platforms from laptops to massively parallel processing systems and implements high level API with C,C++,Fortran and Java interfaces\n* A rich set of integrated performance features that allows for access time and storage space optimizations.\n* Tools and applications to manage, manipulate, view and analyze the data in collection\n\nHDF5Store is a hierarchical dictionary like object that reads and writes pandas objects to the HDF5 format.",
   "metadata": {
    "cell_id": "00044-d57894bc-5c1e-41b5-92fc-a49c4223affb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00045-4ce1a038-9360-42c8-9697-916de10a3288",
    "deepnote_cell_type": "code"
   },
   "source": "# seed for replication\nnp.random.seed(123456)\n# create a DataFrame of dates and random numbers in three columns\ndf = pd.DataFrame(np.random.randn(8,3),index=pd.date_range('1/1/2000', periods=8), columns=['A','B','C'])\n# create HDF5 store\nstore = pd.HDFStore('../../data/store.h5')\nstore['df'] = df # persisting happened here\nstore",
   "outputs": [
    {
     "data": {
      "text/plain": "<class 'pandas.io.pytables.HDFStore'>\nFile path: ../../data/store.h5\n/df            frame        (shape->[8,3])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00046-04b331e7-9114-4bc1-bbbc-b1e38b9291f9",
    "deepnote_cell_type": "code"
   },
   "source": "# read in data from HDF5\nstore = pd.HDFStore(\"../../data/store.h5\")\ndf = store['df']\ndf",
   "outputs": [
    {
     "data": {
      "text/plain": "                   A         B         C\n2000-01-01  0.469112 -0.282863 -1.509059\n2000-01-02 -1.135632  1.212112 -0.173215\n2000-01-03  0.119209 -1.044236 -0.861849\n2000-01-04 -2.104569 -0.494929  1.071804\n2000-01-05  0.721555 -0.706771 -1.039575\n2000-01-06  0.271860 -0.424972  0.567020\n2000-01-07  0.276232 -1.087401 -0.673690\n2000-01-08  0.113648 -1.478427  0.524988"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00047-172928bf-4c95-401d-98b6-cc1ffb1547a1",
    "deepnote_cell_type": "code"
   },
   "source": "# this changes the DataFrame, but did not persist\ndf.ix[0].A = 1\n\n# to persist the change, assign the dataframe to the\n# HDF5 store object\n\nstore['df'] = df\n# it is now persisted\n\n# the following loads the store and\n# shows the first two rows, demonstrating\n# the persisting was done\npd.HDFStore(\"../../data/store.h5\")['df'].head(2)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n  \n"
    },
    {
     "data": {
      "text/plain": "                   A         B         C\n2000-01-01  1.000000 -0.282863 -1.509059\n2000-01-02 -1.135632  1.212112 -0.173215"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Accessing data on the web and in the cloud\n\npandas makes it extremely easy to read data from the web and the cloud. All of the pandas functions we have examined so far can also be given an HTTP URL, FTP address or S3 address instead of a local file path.",
   "metadata": {
    "cell_id": "00048-399dca97-7d61-41b7-b209-8133f6153b21",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00049-df9b2336-6397-4e48-add6-2cefea6be404",
    "deepnote_cell_type": "code"
   },
   "source": "# read csv directly from Yahoo! Finance from a URL\ndf = pd.read_csv(\"https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/AirPassengers.csv\")\ndf[:5]",
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0         time  AirPassengers\n0           1  1949.000000            112\n1           2  1949.083333            118\n2           3  1949.166667            132\n3           4  1949.250000            129\n4           5  1949.333333            121"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Reading and writing from/to SQL databases\n\npandas can read data from any SQL databases that support Python data adapters, that respect the Python DB-API. Reading is performed by using the pandas.io.sql.read_sql() function and writing to SQL databases using the .to_sql() method of DataFrame.",
   "metadata": {
    "cell_id": "00050-712a62ea-88da-471e-944f-43dbb5604cbb",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00051-ed932d51-f486-4911-ac73-ac1aa09bf887",
    "deepnote_cell_type": "code"
   },
   "source": "# reference SQLITE\nimport sqlite3\n\n# read in the stock data from csv\nmsft = pd.read_csv(\"../../data/msft.csv\")\nmsft['Symbol'] = \"MSFT\"\naapl = pd.read_csv(\"../../data/aapl.csv\")\naapl['Symbol'] = 'AAPL'\n\n# create connection\nconnection = sqlite3.connect(\"../../data/stocks.sqlite\")\n# .to_sql() will create sql to store the DataFrame\n# in the specified table. if_exists specifies\n# what to do if the table already exists\n\nmsft.to_sql(\"STOCK DATA\", connection, if_exists=\"replace\")\naapl.to_sql(\"STOCK DATA\", connection, if_exists=\"append\")\n\n# commit the sql and close the connection\nconnection.commit()\nconnection.close()",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:1345: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n  chunksize=chunksize, dtype=dtype)\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00052-d162d8da-f641-44ce-b7df-c882971c4237",
    "deepnote_cell_type": "code"
   },
   "source": "# read data\n# connect to the database file\nconnection = sqlite3.connect(\"../../data/stocks.sqlite\")\n\n# query all records in STOCK_DATA\n# returns a DataFrame\n# index_col specifies which column to make the DataFrame index\nstocks = pd.io.sql.read_sql(\"SELECT * FROM STOCK_DATA;\", connection, index_col=\"index\")\n\n# close the connection\nconnection.close()\n\n# report the head of the data received\nstocks.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "             Date   Open   High    Low  Close   Volume  Adj Close Symbol\nindex                                                                   \n0      2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93   MSFT\n1      2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35   MSFT\n2      2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63   MSFT\n3      2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91   MSFT\n4      2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58   MSFT"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00053-a49bd701-2481-4fb8-a16f-1319f2a04000",
    "deepnote_cell_type": "code"
   },
   "source": "# open the connection\nconnection = sqlite3.connect(\"../../data/stocks.sqlite\")\n\n# construct the query string\nquery = \"SELECT * FROM STOCK_DATA WHERE Volume > 29200100 AND Symbol='MSFT';\"\n\n# execute and close connection\nitems = pd.io.sql.read_sql(query,connection,index_col='index')\nconnection.close()\n\nitems",
   "outputs": [
    {
     "data": {
      "text/plain": "             Date   Open   High    Low  Close    Volume  Adj Close Symbol\nindex                                                                    \n1081   2010-05-21  42.22  42.35  40.99  42.00  33610800      36.48   MSFT\n1097   2010-04-29  46.80  46.95  44.65  45.92  47076200      38.41   MSFT\n1826   2007-06-15  89.80  92.10  89.55  92.04  30656400      35.87   MSFT\n3455   2001-03-16  47.00  47.80  46.10  45.33  40806400      17.66   MSFT\n3712   2000-03-17  49.50  50.00  48.29  50.00  50860500      19.48   MSFT"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "As these functions take a connection object, which can be any Python DB-API compatible data adapter, you can more or less work with any supported database data by simply creating an appropriate connection object. The code at pandas level should remain the same for any supported database.",
   "metadata": {
    "cell_id": "00054-c88600d8-b9ff-4ec1-bd59-0701e7ac9952",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Reading data from remote data services\n\npandas has direct support for various web-based data source classes in the pandas.io.data namespace. The primary class of interest is pandas.io.data.DataReader, which is implemented to read data from various supported sources and return it to the application directly as DataFrame.\n\nCurrently, support exists for the following sources via the DataReader class:\n* Daily historical prices stock from either Yahoo! and Google Finance\n* Yahoo! Options\n* Federal Reserve Economic Data Library\n* Kenneth French's Data Library\n* The World Bank",
   "metadata": {
    "cell_id": "00055-10081537-f775-4233-8bf9-86ce867de4a5",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Reading Stock Data from Yahoo! and Google Finance",
   "metadata": {
    "cell_id": "00056-0f35fca3-ab9d-4c12-b730-f5ebc15b1fd1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00057-236f1ef1-d8fd-4ee8-a745-046d74bc5882",
    "deepnote_cell_type": "code"
   },
   "source": "import pandas_datareader.data as web\nimport datetime\n\n# start and end dates\nstart = datetime.datetime(2012,1,1)\nend = datetime.datetime(2014,1,27)\n\n# read the MSFT stock data from Yahoo!\nyahoo = web.DataReader('MSFT','yahoo',start,end)\nyahoo.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "                 Open       High        Low      Close  Adj Close    Volume\nDate                                                                       \n2012-01-03  26.549999  26.959999  26.389999  26.770000  22.909807  64731500\n2012-01-04  26.820000  27.469999  26.780001  27.400000  23.448965  80516100\n2012-01-05  27.379999  27.730000  27.290001  27.680000  23.688589  56081400\n2012-01-06  27.530001  28.190001  27.530001  28.110001  24.056585  99455500\n2012-01-09  28.049999  28.100000  27.719999  27.740000  23.739935  59706800"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00058-2b0eeb02-f45a-4a9e-af1c-6bbc58a266a9",
    "deepnote_cell_type": "code"
   },
   "source": "# read from google\ngoogle = web.DataReader('MSFT','google',start,end)\ngoogle.head()",
   "outputs": [
    {
     "data": {
      "text/plain": "             Open   High    Low  Close    Volume\nDate                                            \n2016-11-08  60.55  60.78  60.15  60.47  22935355\n2016-11-09  60.00  60.59  59.20  60.17  49632479\n2016-11-10  60.48  60.49  57.63  58.70  57822394\n2016-11-11  58.23  59.12  58.01  59.02  38767843\n2016-11-14  59.02  59.08  57.28  58.12  41328422"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00059-d2c30856-f04a-4d67-9ced-8e133ecf9693",
    "deepnote_cell_type": "code"
   },
   "source": "# specify we want all yahoo options data for AAPL\n# this can take a little time...\nfrom pandas_datareader.data import Options\naapl = Options('AAPL','yahoo')\n# read all the data\ndata = aapl.get_all_data()\n# examine the first six rows and four columns\ndata.iloc[0:6,0:4]",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Last     Bid     Ask   Chg\nStrike Expiry     Type Symbol                                           \n2.5    2017-11-17 call AAPL171117C00002500  160.00  159.40  161.50  6.75\n       2017-12-15 call AAPL171215C00002500  154.95  160.15  161.25  0.00\n       2018-01-19 call AAPL180119C00002500  152.55  153.30  154.05  0.00\n                  put  AAPL180119P00002500    0.02    0.00    0.02  0.00\n       2018-04-20 put  AAPL180420P00002500    0.01    0.00    0.01  0.00\n5.0    2017-11-17 call AAPL171117C00005000  151.80  150.80  151.60  0.00"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00060-3cad6bd1-041c-454b-a8fe-608757c49034",
    "deepnote_cell_type": "code"
   },
   "source": "# get all puts at strike price of $80 (first four columns only)\ndata.loc[(80, slice(None),'put'),:].iloc[0:5,0:4]",
   "outputs": [
    {
     "data": {
      "text/plain": "                                            Last   Bid   Ask   Chg\nStrike Expiry     Type Symbol                                     \n80.0   2017-11-17 put  AAPL171117P00080000  0.01  0.00  0.05  0.00\n       2017-12-15 put  AAPL171215P00080000  0.01  0.00  0.01  0.00\n       2018-01-19 put  AAPL180119P00080000  0.01  0.00  0.02 -0.01\n       2018-02-16 put  AAPL180216P00080000  0.02  0.00  0.03 -0.01\n       2018-04-20 put  AAPL180420P00080000  0.10  0.06  0.14  0.00"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00061-b458460d-8295-49c4-946a-daa54bb01211",
    "deepnote_cell_type": "code"
   },
   "source": "data.loc[(80,slice('20150117','20150417'),'put'),:].iloc[:,0:4]",
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [Last, Bid, Ask, Chg]\nIndex: []"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00062-4603d8cf-cefd-425b-8d45-dbc355cee38f",
    "deepnote_cell_type": "code"
   },
   "source": "# msft calls expiring on 2015-01-05\nexpiry = datetime.date(2015, 1, 5)\nmsft_calls = Options('MSFT','yahoo').get_call_data(expiry=expiry)\nmsft_calls.iloc[0:5,0:5]",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Last    Bid    Ask  Chg  PctChg\nStrike Expiry     Type Symbol                                               \n60.0   2017-11-10 call MSFT171110C00060000  15.05  18.75  18.90  0.0     0.0\n65.0   2017-11-10 call MSFT171110C00065000  13.85  17.85  19.40  0.0     0.0\n67.0   2017-11-10 call MSFT171110C00067000  17.25   0.00   0.00  0.0     0.0\n67.5   2017-11-10 call MSFT171110C00067500   9.05  11.30  11.45  0.0     0.0\n68.0   2017-11-10 call MSFT171110C00068000   7.80  10.80  10.95  0.0     0.0"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00063-4ac4dd77-491f-41d0-9c2c-6000d7128cc4",
    "deepnote_cell_type": "code"
   },
   "source": "# msft calls expiring on 2015-01-17\nexpiry = datetime.date(2015,1,17)\naapl_calls = aapl.get_call_data(expiry=expiry)\naapl_calls.iloc[0:5,0:4]",
   "outputs": [
    {
     "data": {
      "text/plain": "                                             Last   Bid    Ask       Chg\nStrike Expiry     Type Symbol                                           \n105.0  2017-11-10 call AAPL171110C00105000  69.85   0.0   0.00  0.000000\n110.0  2017-11-10 call AAPL171110C00110000  62.35   0.0   0.00  0.000000\n115.0  2017-11-10 call AAPL171110C00115000  59.85   0.0   0.00  0.000000\n120.0  2017-11-10 call AAPL171110C00120000  51.98  52.2  52.75  8.849998\n125.0  2017-11-10 call AAPL171110C00125000  32.35  37.2  39.05  0.000000"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Reading from Federal Reserve Economic Data",
   "metadata": {
    "cell_id": "00064-ec611834-09b4-4eb1-86d5-e2ae47843ec2",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00065-1106f119-6ee2-4233-95c3-af95ce30e58b",
    "deepnote_cell_type": "code"
   },
   "source": "gdp = web.DataReader(\"GDP\",\"fred\",datetime.date(2012,1,1),datetime.date(2014,1,27))\ngdp",
   "outputs": [
    {
     "data": {
      "text/plain": "                  GDP\nDATE                 \n2012-01-01  15973.881\n2012-04-01  16121.851\n2012-07-01  16227.939\n2012-10-01  16297.349\n2013-01-01  16475.440\n2013-04-01  16541.390\n2013-07-01  16749.349\n2013-10-01  16999.888\n2014-01-01  17031.324"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00066-7b17c7b6-4197-4a03-82db-5188f69ee1d2",
    "deepnote_cell_type": "code"
   },
   "source": "# get compensation of employees: Wages and Salaries\nweb.DataReader(\"A576RC1A027NBEA\",\"fred\",datetime.date(1929,1,1),datetime.date(2013,1,1))",
   "outputs": [
    {
     "data": {
      "text/plain": "            A576RC1A027NBEA\nDATE                       \n1929-01-01             50.5\n1930-01-01             46.2\n1931-01-01             39.2\n1932-01-01             30.5\n1933-01-01             29.0\n...                     ...\n2009-01-01           6251.4\n2010-01-01           6377.5\n2011-01-01           6633.2\n2012-01-01           6930.3\n2013-01-01           7114.4\n\n[85 rows x 1 columns]"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Accessing Kenneth French's Data\n\nKenneth R French is a professor of finance at Tuck School of Business at Dartmouth University. He has created an extensive library of economic data, which is available for download over the Web.",
   "metadata": {
    "cell_id": "00067-a58f9caa-03a0-44d7-ac53-a95802e399b3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00068-f579f96f-f5b8-4a34-b5b7-7f2d9af1f851",
    "deepnote_cell_type": "code"
   },
   "source": "# read from Kenneth French fama global factors data set\nfactors = web.DataReader(\"Global_Factors\",\"famafrench\")\nfactors",
   "outputs": [
    {
     "data": {
      "text/plain": "{0:          Mkt-RF   SMB   HML   WML    RF\n Date                                   \n 2010-01   -3.70  2.70 -0.29 -2.23  0.00\n 2010-02    1.24  0.14  0.10  1.59  0.00\n 2010-03    6.30 -0.26  3.18  4.26  0.01\n 2010-04    0.44  3.78  0.77  1.60  0.01\n 2010-05   -9.52  0.17 -2.54 -0.56  0.01\n ...         ...   ...   ...   ...   ...\n 2015-09   -3.91 -0.28 -0.89  3.47  0.00\n 2015-10    7.30 -2.26  0.21 -2.62  0.00\n 2015-11   -0.30  1.69 -1.78  2.11  0.00\n 2015-12   -1.74  0.93 -1.79  3.28  0.01\n 2016-01   -6.29 -2.10  0.97  0.51  0.01\n \n [73 rows x 5 columns], 1:       Mkt-RF    SMB    HML    WML    RF\n Date                                   \n 2010   13.94  12.62  -5.14  13.93  0.12\n 2011   -6.79  -5.41  -4.76   6.30  0.04\n 2012   16.87  -2.55   6.41   6.35  0.06\n 2013   28.61  -0.46   5.07  23.68  0.02\n 2014    3.30  -5.03  -3.88   0.79  0.02\n 2015   -0.50   3.86 -11.12  17.10  0.02, 'DESCR': 'Global Factors\\n--------------\\n\\nThis file was created using the 201601 Bloomberg database. Missing data are indicated by -99.99. \\n\\n  0 : (73 rows x 5 cols)\\n  1 : Annual Factors: January-December (6 rows x 5 cols)'}"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Reading from the World Bank\n\nWorld Bank datasets are identified using indicators, a text code that represents each dataset. A full list of indicators can be retrieved using the pandas_datareader.get_indicators() function.",
   "metadata": {
    "cell_id": "00069-6363bd74-c5fe-400b-a214-1c3f415bd1f1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00070-a5741baf-607e-4d9e-b28d-9591bec8346c",
    "deepnote_cell_type": "code"
   },
   "source": "from pandas_datareader import wb\nall_indicators = wb.get_indicators()\n# examine some of the indicators\nall_indicators.ix[:,0:1]",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n  after removing the cwd from sys.path.\n"
    },
    {
     "data": {
      "text/plain": "                               id\n0              1.0.HCount.1.90usd\n1               1.0.HCount.2.5usd\n2            1.0.HCount.Mid10to50\n3                 1.0.HCount.Ofcl\n4             1.0.HCount.Poor4uds\n...                           ...\n16931    per_sionl.overlap_q1_rur\n16932    per_sionl.overlap_q1_tot\n16933    per_sionl.overlap_q1_urb\n16934     s_policyholders_B2_life\n16935  s_policyholders_B2_nonlife\n\n[16936 rows x 1 columns]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00071-b945ebd3-fead-4c5e-803d-6bb52d3b8e3f",
    "deepnote_cell_type": "code"
   },
   "source": "# search of life expectancy indicators\nle_indicators = wb.search(\"life expectancy\")\nle_indicators.iloc[:3,:2]",
   "outputs": [
    {
     "data": {
      "text/plain": "                      id                                               name\n9011         SE.SCH.LIFE  School life expectancy, primary to tertiary, b...\n10312  SP.DYN.LE00.FE.IN           Life expectancy at birth, female (years)\n10313     SP.DYN.LE00.IN            Life expectancy at birth, total (years)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00072-afb8dce0-4b86-457f-8197-07de06286b4f",
    "deepnote_cell_type": "code"
   },
   "source": "# get countries and show the 3 digit code and name\ncountries = wb.get_countries()\n# show a subset of the country data\ncountries.iloc[0:10].ix[:,['name','capitalcity','iso2c']]",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: \n.ix is deprecated. Please use\n.loc for label based indexing or\n.iloc for positional indexing\n\nSee the documentation here:\nhttp://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n  after removing the cwd from sys.path.\n"
    },
    {
     "data": {
      "text/plain": "                   name  capitalcity iso2c\n0                 Aruba          NaN    AW\n1           Afghanistan          NaN    AF\n2                Africa          NaN    A9\n3                Angola          NaN    AO\n4               Albania          NaN    AL\n5               Andorra          NaN    AD\n6         Andean Region          NaN    L5\n7            Arab World          NaN    1A\n8  United Arab Emirates          NaN    AE\n9             Argentina          NaN    AR"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00073-d452b317-9f82-4854-bb8a-d5d95e790b4b",
    "deepnote_cell_type": "code"
   },
   "source": "# get life expectancy at birth for all countries from 1980 to 2014\nle_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", start='1980',end='2014')\nle_data_all",
   "outputs": [
    {
     "data": {
      "text/plain": "                    SP.DYN.LE00.IN\ncountry       year                \nCanada        2014       81.953049\n              2013       81.772049\n              2012       81.583512\n              2011       81.448780\n              2010       81.197561\n...                            ...\nUnited States 1984       74.563415\n              1983       74.463415\n              1982       74.360976\n              1981       74.009756\n              1980       73.609756\n\n[105 rows x 1 columns]"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00074-91c76913-312c-4230-a9b0-2fe108cf070a",
    "deepnote_cell_type": "code"
   },
   "source": "# only US, CAN and MEX are returned by default\nle_data_all.index.levels[0]",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Canada', 'Mexico', 'United States'], dtype='object', name='country')"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00075-38f9ac5a-a75a-478e-88d5-b8e35c54b29e",
    "deepnote_cell_type": "code"
   },
   "source": "# retrieve life expectancy at birth for all countries\n# from 1980 to 2014\nle_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\",country=countries['iso2c'],start='1980',end='2012')\nle_data_all",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/cnc/anaconda/lib/python3.6/site-packages/pandas_datareader/wb.py:145: UserWarning: Non-standard ISO country codes: 1A, 1W, 4E, 6D, 6F, 6L, 6N, 6X, 7E, 8S, A4, A5, A9, B1, B2, B3, B4, B6, B7, B8, C4, C5, C6, C7, C8, C9, D2, D3, D4, D5, D6, D7, D8, D9, EU, F1, F6, JG, L4, L5, L6, L7, M1, M2, N6, O6, OE, R6, S1, S2, S3, S4, T2, T3, T4, T5, T6, T7, V1, V2, V3, V4, XC, XD, XE, XF, XG, XH, XI, XJ, XK, XL, XM, XN, XO, XP, XQ, XT, XU, XY, Z4, Z7, ZB, ZF, ZG, ZJ, ZQ, ZT\n  'country codes: %s' % tmp, UserWarning)\n"
    },
    {
     "data": {
      "text/plain": "               SP.DYN.LE00.IN\ncountry  year                \nAruba    2012       75.183195\n         2011       75.047659\n         2010       74.910634\n         2009       74.771146\n         2008       74.627683\n...                       ...\nZimbabwe 1984       60.932756\n         1983       60.711585\n         1982       60.350878\n         1981       59.886049\n         1980       59.355561\n\n[8679 rows x 1 columns]"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "We can do some interesting things with this data. The example we will look at, determines which country has the lowest life expectancy for each year. To do this, we first need to pivot this data, so that the index is the country name and the year is the column.",
   "metadata": {
    "cell_id": "00076-e3d3b984-418e-4ae4-ba96-12adf5b5e74d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00077-05d33369-c648-4937-8ecb-e0b72f327578",
    "deepnote_cell_type": "code"
   },
   "source": "# le_data_all.pivot(index='country',columns='year')\nle_data = le_data_all.reset_index().pivot(index='country',columns='year')\n# examine pivoted data\nle_data.iloc[:,0:3]",
   "outputs": [
    {
     "data": {
      "text/plain": "                   SP.DYN.LE00.IN                      \nyear                         1980       1981       1982\ncountry                                                \nAfghanistan             41.875244  42.533610  43.235902\nAlbania                 70.235976  70.454463  70.685122\nAlgeria                 58.164024  59.486756  60.786341\nAmerican Samoa                NaN        NaN        NaN\nAndorra                       NaN        NaN        NaN\n...                           ...        ...        ...\nWest Bank and Gaza            NaN        NaN        NaN\nWorld                   62.865800  63.200694  63.519298\nYemen, Rep.             50.559537  51.541341  52.492707\nZambia                  51.248293  50.943171  50.514366\nZimbabwe                59.355561  59.886049  60.350878\n\n[263 rows x 3 columns]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00078-4b44cd2b-543e-4d43-8696-6a22a2a260b0",
    "deepnote_cell_type": "code"
   },
   "source": "# ask what is the name of the country for each year\n# with the least life expectancy\ncountry_with_least_expectancy = le_data.idxmin(axis=0)\ncountry_with_least_expectancy",
   "outputs": [
    {
     "data": {
      "text/plain": "                year\nSP.DYN.LE00.IN  1980                    Cambodia\n                1981                    Cambodia\n                1982                 Timor-Leste\n                1983                 South Sudan\n                1984                 South Sudan\n                                  ...           \n                2008    Central African Republic\n                2009    Central African Republic\n                2010    Central African Republic\n                2011    Central African Republic\n                2012    Central African Republic\nLength: 33, dtype: object"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00079-38fe2a45-9f93-4625-9591-7e7e12d4e46c",
    "deepnote_cell_type": "code"
   },
   "source": "# and what is the minimum life expectancy for each year\nexpectancy_for_least_country = le_data.min(axis=0)\nexpectancy_for_least_country",
   "outputs": [
    {
     "data": {
      "text/plain": "                year\nSP.DYN.LE00.IN  1980    27.738976\n                1981    33.449927\n                1982    38.186220\n                1983    39.666488\n                1984    39.999537\n                          ...    \n                2008    46.163171\n                2009    46.834927\n                2010    47.532707\n                2011    48.256976\n                2012    49.012146\nLength: 33, dtype: float64"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00080-d0091958-55de-4456-b8b8-24a60a430670",
    "deepnote_cell_type": "code"
   },
   "source": "# this merges the two frames together and gives us\n# year, country and expectancy where the minimum exists\nleast = pd.DataFrame(data={'Country':country_with_least_expectancy.values,\n                          'Expectancy':expectancy_for_least_country.values},\n                    index= country_with_least_expectancy.index.levels[1])\nleast",
   "outputs": [
    {
     "data": {
      "text/plain": "                       Country  Expectancy\nyear                                      \n1980                  Cambodia   27.738976\n1981                  Cambodia   33.449927\n1982               Timor-Leste   38.186220\n1983               South Sudan   39.666488\n1984               South Sudan   39.999537\n...                        ...         ...\n2008  Central African Republic   46.163171\n2009  Central African Republic   46.834927\n2010  Central African Republic   47.532707\n2011  Central African Republic   48.256976\n2012  Central African Republic   49.012146\n\n[33 rows x 2 columns]"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "cell_id": "00081-4c0dc29a-bb1e-487d-9620-fb7f4f3d5b63",
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=30b5f66f-e6a5-4e83-8134-c70f8eed277d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "deepnote_notebook_id": "6fa9448b-036a-4b1f-b0fb-6e356de4d7b8",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}