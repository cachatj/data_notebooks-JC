{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check workDir\n",
    "\n",
    "import os\n",
    "\t\n",
    "def current_path():\n",
    "\tprint(\"Current working directory before\")\n",
    "\tprint(os.getcwd())\n",
    "\tprint()\n",
    "\t\n",
    "# Changing the Working Dir = CH MacBook Pro (Work)\n",
    "#os.chdir('/Volumes/GoogleDrive/.shortcut-targets-by-id/1xylucPMaXcsFZGYrVPyCeU24c8NA4yTR/JupyterNB-All/00-workingDir')\n",
    "\n",
    "# Printing CWD after\n",
    "current_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller, kpss, acf, grangercausalitytests\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf,month_plot,quarter_plot\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline \n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rc('xtick', labelsize=15) \n",
    "plt.rc('ytick', labelsize=15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect proper working dir & data folder\n",
    "\n",
    "inputData1 = pd.read_csv('/Volumes/GoogleDrive/.shortcut-targets-by-id/1O_LCvBhBN7-B1UdZ58UM2h6cqnW4ZumD/JupyterNB-JC/00-data/timeseries_data-Temperature-Salinity.csv',\n",
    " usecols=['id','obs_id','year_month','temperatureSurface','salinitySurface'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = inputData1\n",
    "data['year_month'] = pd.to_datetime(data['year_month'])\n",
    "data['year'] = data['year_month'].dt.year\n",
    "data['month'] = data['year_month'].dt.month\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time series data, the obvious graph to start with is a time plot. That is, the observations are plotted against the time of observation, with consecutive observations joined by straight lines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "d = data[data['obs_id']==2]\n",
    "sns.lineplot(d['year_month'], d['salinitySurface'] )\n",
    "\n",
    "ax.set_title('Salinity over Time', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\n",
    "ax.set_xlabel('Year', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "ax.set_ylabel('Salinity', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "plt.tick_params(axis='y', which='major', labelsize=16)\n",
    "plt.tick_params(axis='x', which='major', labelsize=16)\n",
    "ax.yaxis.tick_left() # where the y axis marks will be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly data show strong seasonality within each year. There is no cyclic behavior and no trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Plot and Box Plots\n",
    "\n",
    "A seasonal plot is similar to a time plot except that the data are plotted against the individual “seasons” in which the data were observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variable = 'salinitySurface'\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "palette = sns.color_palette(\"ch:2.5,-.2,dark=.3\", 10)\n",
    "sns.lineplot(d['month'], d[variable], hue=d['year'], palette=palette)\n",
    "ax.set_title('Seasonal plot of Salinity', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\n",
    "ax.set_xlabel('Month', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "ax.set_ylabel('Salinity Surface', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))\n",
    "\n",
    "sns.boxplot(d['year'], d[variable], ax=ax[0])\n",
    "ax[0].set_title('Year-wise Box Plot\\n(The Trend)', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\n",
    "ax[0].set_xlabel('Year', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "ax[0].set_ylabel('Salinity Surface', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "\n",
    "sns.boxplot(d['month'], d[variable], ax=ax[1])\n",
    "ax[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize = 20, loc='center', fontdict=dict(weight='bold'))\n",
    "ax[1].set_xlabel('Month', fontsize = 16, fontdict=dict(weight='bold'))\n",
    "ax[1].set_ylabel('Salinity Surface', fontsize = 16, fontdict=dict(weight='bold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Subseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data['obs_id']==2][['year_month','temperatureSurface','salinitySurface']]\n",
    "y = y.set_index('year_month')\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "month_plot(y['temperatureSurface'],ylabel='TemperatureSurface', ax=ax[0]);\n",
    "month_plot(y['salinitySurface'],ylabel='SalinitySurface', ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data['obs_id']==2][['year_month','temperatureSurface']]\n",
    "y = y.set_index('year_month')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = data[data['obs_id']==2][['year_month','temperatureSurface']]\n",
    "y = y.set_index('year_month')\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 12\n",
    "rcParams['axes.labelsize'] = 20\n",
    "rcParams['ytick.labelsize'] = 16\n",
    "rcParams['xtick.labelsize'] = 16\n",
    "decomposition = sm.tsa.seasonal_decompose(y, model='additive')\n",
    "decomp = decomposition.plot()\n",
    "decomp.suptitle('Temperature Decomposition', fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hodrick-Prescott filter separates a time-series yt into a trend component τ and a cyclical component ct. For monthly data lambda=129,600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "\n",
    "gdp_cycle, gdp_trend = hpfilter(y['temperatureSurface'], lamb=129600)\n",
    "y['trend'] = gdp_trend\n",
    "y['cycle'] = gdp_cycle\n",
    "\n",
    "y[['trend','temperatureSurface','cycle']].plot(figsize=(15,6)).autoscale(axis='x',tight=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the strength of trend. 0 for low, 1 for high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(0,(1-decomposition.resid.var()/(decomposition.resid+decomposition.trend).var())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure the strength of seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(0,(1-decomposition.resid.var()/(decomposition.resid+decomposition.seasonal).var())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended = signal.detrend(data[data['obs_id']==2][['year_month','temperatureSurface']]['temperatureSurface'].values)\n",
    "plt.plot(detrended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "# check for stationarity\n",
    "def adf_test(series,title=''):\n",
    "    \"\"\"\n",
    "    Pass in a time series and an optional title, returns an ADF report\n",
    "    \"\"\"\n",
    "    print('Augmented Dickey-Fuller Test: {}'.format(title))\n",
    "    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n",
    "    \n",
    "    labels = ['ADF test statistic','p-value','# lags used','# observations']\n",
    "    out = pd.Series(result[0:4],index=labels)\n",
    "\n",
    "    for key,val in result[4].items():\n",
    "        out['critical value ({})'.format(key)]=val\n",
    "        \n",
    "    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Strong evidence against the null hypothesis\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against the null hypothesis\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(\"Data has a unit root and is non-stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(data[data['obs_id']==2][['year_month','temperatureSurface']]['temperatureSurface'],title='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# KPSS Test\n",
    "result = kpss(data[data['obs_id']==2][['year_month','temperatureSurface']]['temperatureSurface'].values, regression='c')\n",
    "print(\"\\nKPSS Statistic: {}\".format(result[0]))\n",
    "print(\"P-Value: {}\".format(result[1]))\n",
    "for key, value in result[3].items():\n",
    "    print('Critial Values:')\n",
    "    print(\"   {}, {}\".format(key,value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ADF test, the null hypothesis is the time series possesses a unit root and is non-stationary. So because the P-Value is <0.05 we reject the null hypothesis.\n",
    "\n",
    "The KPSS test, on the other hand, is used to test for trend stationarity. The null hypothesis and the P-Value interpretation is just the opposite of ADH test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Granger Causality Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially we're looking for extremely low p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grangercausalitytests(data[data['obs_id']==2][['temperatureSurface','salinitySurface']],maxlag=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one time series is useful in forecasting the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful type of plot to explore the relationship between each observation and a lag of that observation is called the scatter plot.\n",
    "\n",
    "Pandas has a built-in function for exactly this called the lag plot. It plots the observation at time t on the x-axis and the lag1 observation (t-1) on the y-axis.\n",
    "\n",
    "- If the points cluster along a diagonal line from the bottom-left to the top-right of the plot, it suggests a positive correlation relationship.\n",
    "- If the points cluster along a diagonal line from the top-left to the bottom-right, it suggests a negative correlation relationship.\n",
    "- Either relationship is good as they can be modeled.\n",
    "- More points tighter in to the diagonal line suggests a stronger relationship and more spread from the line suggests a weaker relationship.\n",
    "- A ball in the middle or a spread across the plot suggests a weak or no relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag PLots\n",
    "from pandas.plotting import lag_plot\n",
    "lag_plot(data[data['obs_id']==2]['temperatureSurface']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(15, 6))\n",
    "autocorr = acf(data[variable], nlags=60) # just the numbers\n",
    "plot_acf(data['temperatureSurface'].tolist(), lags=60, ax=ax[0]); # just the plot\n",
    "plot_pacf(data['temperatureSurface'].tolist(), lags=60, ax=ax[1]); # just the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Moving Average, expanding and Exponentially Weighted Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[data['obs_id']==2][['year_month','salinitySurface']]\n",
    "y = y.set_index('year_month')\n",
    "y['SMA3'] = y.rolling(window=3).mean() \n",
    "y.plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = data[data['obs_id']==2][['year_month','salinitySurface']]\n",
    "y1 = y1.set_index('year_month')\n",
    "y1['salinitySurface'].expanding().mean().plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "\n",
    "span = 3\n",
    "alpha = 2/(span+1)\n",
    "y.index.freq = 'MS'\n",
    "y['SES3']=SimpleExpSmoothing(y['salinitySurface']).fit(smoothing_level=alpha,optimized=False).fittedvalues.shift(-1)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double Exponential Smoothing\n",
    "Where Simple Exponential Smoothing employs just one smoothing factor $\\alpha$ (alpha), Double Exponential Smoothing adds a second smoothing factor $\\beta$ (beta) that addresses trends in the data. Like the alpha factor, values for the beta factor fall between zero and one ($0<\\beta≤1$). The benefit here is that the model can anticipate future increases or decreases where the level model would only work from recent calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "y['DESadd3'] = ExponentialSmoothing(y['salinitySurface'], trend='add').fit().fittedvalues.shift(-1)\n",
    "y[['salinitySurface', 'SES3', 'DESadd3']].iloc[:12].plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triple Exponential Smoothing\n",
    "Triple Exponential Smoothing, the method most closely associated with Holt-Winters, adds support for both trends and seasonality in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y['TESadd3'] = ExponentialSmoothing(y['salinitySurface'],trend='add',seasonal='add',seasonal_periods=12).fit().fittedvalues.shift(-1)\n",
    "\n",
    "y[['salinitySurface', 'TESadd3', 'DESadd3']].plot(figsize=(15,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple forecasting methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average method\n",
    "Here, the forecasts of all future values are equal to the mean of the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve method\n",
    "For naïve forecasts, we simply set all forecasts to be the value of the last observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal naïve method\n",
    "In this case, we set each forecast to be equal to the last observed value from the same season of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drift method\n",
    "A variation on the naïve method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the drift) is set to be the average change seen in the historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
